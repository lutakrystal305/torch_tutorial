{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch(Lr-autograd).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO+ASRzIlGvbRRsaT50DOWA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lutakrystal305/torch_tutorial/blob/main/PyTorch(Lr_autograd).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5btZMCWKKnyD",
        "outputId": "d117e30a-b261-482e-9ae2-ceb8e087b93f"
      },
      "source": [
        "!pip install torchviz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchviz\n",
            "  Downloading https://files.pythonhosted.org/packages/79/e7/643808913211d6c1fc96a3a4333bf4c9276858fab00bcafaf98ea58a97be/torchviz-0.0.2.tar.gz\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchviz) (1.9.0+cu102)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchviz) (3.7.4.3)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.2-cp37-none-any.whl size=4152 sha256=040027ff575d582854580e17e1d2dcbf2735afcb2b75b5bc5430bd3553503746\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/26/58/026ffd533dbe8b3972eb423da9c7949beca68d1c98ed9e8624\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ow3gagDNvoX"
      },
      "source": [
        "import torch\n",
        "from torchviz import make_dot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RydoxLa-N2YN"
      },
      "source": [
        "x = torch.tensor([3])\n",
        "y = torch.tensor([10])\n",
        "a = torch.tensor([1.], requires_grad = True)\n",
        "b = torch.tensor([2.], requires_grad= True)\n",
        "\n",
        "y_hat = a*x+b\n",
        "z = y_hat - y\n",
        "L = z**2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-4keBdZPNLW",
        "outputId": "74e153fe-9235-4c92-e5bb-53cee865a664"
      },
      "source": [
        "L.backward()\n",
        "print(a.grad) # -30\n",
        "print(b.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-30.])\n",
            "tensor([-10.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItJzbx9aPp_B",
        "outputId": "530fa4ad-05a9-4556-8dba-a72468ba15b3"
      },
      "source": [
        "print(x.grad_fn) # None\n",
        "print(a.grad_fn) # None\n",
        "print(y_hat.grad_fn) # AddBackward0 \n",
        "print(z.grad_fn) # SubBackward0 \n",
        "print(L.grad_fn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n",
            "None\n",
            "<AddBackward0 object at 0x7fa72cb89f90>\n",
            "<SubBackward0 object at 0x7fa72cb89f10>\n",
            "<PowBackward0 object at 0x7fa72cb89090>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "j6qHi_NrPfm1",
        "outputId": "d8620319-4341-436a-c9f2-e7252a07fb0b"
      },
      "source": [
        "make_dot(L)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7fa72cb89f50>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"222pt\" height=\"393pt\"\n viewBox=\"0.00 0.00 222.00 393.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 389)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-389 218,-389 218,4 -4,4\"/>\n<!-- 140355986417376 -->\n<g id=\"node1\" class=\"node\">\n<title>140355986417376</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"133.5,-31 79.5,-31 79.5,0 133.5,0 133.5,-31\"/>\n<text text-anchor=\"middle\" x=\"106.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 140355986559120 -->\n<g id=\"node2\" class=\"node\">\n<title>140355986559120</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"151,-86 62,-86 62,-67 151,-67 151,-86\"/>\n<text text-anchor=\"middle\" x=\"106.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">PowBackward0</text>\n</g>\n<!-- 140355986559120&#45;&gt;140355986417376 -->\n<g id=\"edge8\" class=\"edge\">\n<title>140355986559120&#45;&gt;140355986417376</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M106.5,-66.9688C106.5,-60.1289 106.5,-50.5621 106.5,-41.5298\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"110.0001,-41.3678 106.5,-31.3678 103.0001,-41.3678 110.0001,-41.3678\"/>\n</g>\n<!-- 140355986562832 -->\n<g id=\"node3\" class=\"node\">\n<title>140355986562832</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"151,-141 62,-141 62,-122 151,-122 151,-141\"/>\n<text text-anchor=\"middle\" x=\"106.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">SubBackward0</text>\n</g>\n<!-- 140355986562832&#45;&gt;140355986559120 -->\n<g id=\"edge1\" class=\"edge\">\n<title>140355986562832&#45;&gt;140355986559120</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M106.5,-121.9197C106.5,-114.9083 106.5,-105.1442 106.5,-96.4652\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"110.0001,-96.3408 106.5,-86.3408 103.0001,-96.3409 110.0001,-96.3408\"/>\n</g>\n<!-- 140355986562960 -->\n<g id=\"node4\" class=\"node\">\n<title>140355986562960</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"151,-196 62,-196 62,-177 151,-177 151,-196\"/>\n<text text-anchor=\"middle\" x=\"106.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AddBackward0</text>\n</g>\n<!-- 140355986562960&#45;&gt;140355986562832 -->\n<g id=\"edge2\" class=\"edge\">\n<title>140355986562960&#45;&gt;140355986562832</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M106.5,-176.9197C106.5,-169.9083 106.5,-160.1442 106.5,-151.4652\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"110.0001,-151.3408 106.5,-141.3408 103.0001,-151.3409 110.0001,-151.3408\"/>\n</g>\n<!-- 140355986562704 -->\n<g id=\"node5\" class=\"node\">\n<title>140355986562704</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"95,-251 6,-251 6,-232 95,-232 95,-251\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">MulBackward0</text>\n</g>\n<!-- 140355986562704&#45;&gt;140355986562960 -->\n<g id=\"edge3\" class=\"edge\">\n<title>140355986562704&#45;&gt;140355986562960</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M60.2545,-231.9197C68.1865,-224.1293 79.5788,-212.9405 89.0712,-203.6176\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"91.7982,-205.845 96.4802,-196.3408 86.8932,-200.8509 91.7982,-205.845\"/>\n</g>\n<!-- 140355986559632 -->\n<g id=\"node6\" class=\"node\">\n<title>140355986559632</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"101,-312 0,-312 0,-293 101,-293 101,-312\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-300\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 140355986559632&#45;&gt;140355986562704 -->\n<g id=\"edge4\" class=\"edge\">\n<title>140355986559632&#45;&gt;140355986562704</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M50.5,-292.9688C50.5,-284.5131 50.5,-271.8901 50.5,-261.2615\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"54.0001,-261.1656 50.5,-251.1656 47.0001,-261.1657 54.0001,-261.1656\"/>\n</g>\n<!-- 140355986469984 -->\n<g id=\"node7\" class=\"node\">\n<title>140355986469984</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"77.5,-385 23.5,-385 23.5,-354 77.5,-354 77.5,-385\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-361\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 140355986469984&#45;&gt;140355986559632 -->\n<g id=\"edge5\" class=\"edge\">\n<title>140355986469984&#45;&gt;140355986559632</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M50.5,-353.9604C50.5,-344.6356 50.5,-332.6748 50.5,-322.6317\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"54.0001,-322.35 50.5,-312.3501 47.0001,-322.3501 54.0001,-322.35\"/>\n</g>\n<!-- 140355986559888 -->\n<g id=\"node8\" class=\"node\">\n<title>140355986559888</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"214,-251 113,-251 113,-232 214,-232 214,-251\"/>\n<text text-anchor=\"middle\" x=\"163.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 140355986559888&#45;&gt;140355986562960 -->\n<g id=\"edge6\" class=\"edge\">\n<title>140355986559888&#45;&gt;140355986562960</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M153.5714,-231.9197C145.4169,-224.0514 133.6697,-212.7164 123.9508,-203.3385\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"126.3252,-200.7659 116.6987,-196.3408 121.4646,-205.8032 126.3252,-200.7659\"/>\n</g>\n<!-- 140355986451264 -->\n<g id=\"node9\" class=\"node\">\n<title>140355986451264</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"190.5,-318 136.5,-318 136.5,-287 190.5,-287 190.5,-318\"/>\n<text text-anchor=\"middle\" x=\"163.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 140355986451264&#45;&gt;140355986559888 -->\n<g id=\"edge7\" class=\"edge\">\n<title>140355986451264&#45;&gt;140355986559888</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M163.5,-286.791C163.5,-279.0249 163.5,-269.5706 163.5,-261.3129\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"167.0001,-261.0647 163.5,-251.0648 160.0001,-261.0648 167.0001,-261.0647\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWG61U8_Pfv2",
        "outputId": "a62e1661-8a67-4e9b-f5a3-3160a146441d"
      },
      "source": [
        "!git clone https://github.com/nttuan8/Pytorch_tutorial.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Pytorch_tutorial'...\n",
            "remote: Enumerating objects: 38, done.\u001b[K\n",
            "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 38 (delta 8), reused 29 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (38/38), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fx_oMf7VQHff"
      },
      "source": [
        "!mv \"/content/Pytorch_tutorial/L2/data_linear.csv\" \"/content/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7v8ttvREQQx-"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48u7qw2SQbNF",
        "outputId": "2830bed8-0579-479e-e688-a4103ea275f1"
      },
      "source": [
        "data = pd.read_csv('data_linear.csv').values\n",
        "print(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  30.      448.524 ]\n",
            " [  32.4138  509.248 ]\n",
            " [  34.8276  535.104 ]\n",
            " [  37.2414  551.432 ]\n",
            " [  39.6552  623.418 ]\n",
            " [  42.069   625.992 ]\n",
            " [  44.4828  655.248 ]\n",
            " [  46.8966  701.377 ]\n",
            " [  49.3103  748.918 ]\n",
            " [  51.7241  757.881 ]\n",
            " [  54.1379  831.004 ]\n",
            " [  56.5517  855.409 ]\n",
            " [  58.9655  866.707 ]\n",
            " [  61.3793  902.545 ]\n",
            " [  63.7931  952.261 ]\n",
            " [  66.2069  995.531 ]\n",
            " [  68.6207 1069.78  ]\n",
            " [  71.0345 1074.42  ]\n",
            " [  73.4483 1103.88  ]\n",
            " [  75.8621 1138.69  ]\n",
            " [  78.2759 1153.13  ]\n",
            " [  80.6897 1240.27  ]\n",
            " [  83.1034 1251.9   ]\n",
            " [  85.5172 1287.97  ]\n",
            " [  87.931  1320.47  ]\n",
            " [  90.3448 1374.92  ]\n",
            " [  92.7586 1410.16  ]\n",
            " [  95.1724 1469.69  ]\n",
            " [  97.5862 1478.54  ]\n",
            " [ 100.     1515.28  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4360v4EQmOx"
      },
      "source": [
        "x = torch.tensor(data[:, 0])\n",
        "y = torch.tensor(data[:, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMeUWkOfQ9yC"
      },
      "source": [
        "def model(x, a, b):\n",
        "    return a*x+b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwOb7nYFRDq6"
      },
      "source": [
        "def loss_fn(y_hat, y):\n",
        "    square_diff = (y_hat-y)**2\n",
        "    print(square_diff.mean())\n",
        "    print(square_diff)\n",
        "    return square_diff.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJkEohFiRVKb"
      },
      "source": [
        "def training(epochs, lr, params, x, y):\n",
        "    a, b = params\n",
        "    #Lưu loss qua epoch để vẽ đồ thị loss\n",
        "    losses = []\n",
        "    for epoch in range(1, epochs+1):\n",
        "        if a.grad is not None:\n",
        "            a.grad.zero_()\n",
        "        if b.grad is not None:\n",
        "            b.grad.zero_()\n",
        "        \n",
        "        y_hat = model(x, a, b)\n",
        "        print('y_hat:', y_hat)\n",
        "        loss = loss_fn(y_hat, y)\n",
        "\n",
        "        #Gọi backward để tính đạo hàm ngược của loss với a, b\n",
        "        loss.backward()\n",
        "        \n",
        "        #update a, b  bằng thuật toán gradient descent, để torch.no_grad để khỏi phải gọi lại backward ở bước này\n",
        "        with torch.no_grad():\n",
        "            a -= lr * a.grad\n",
        "            b -= lr * b.grad\n",
        "        if epoch % 1 == 0:\n",
        "            losses.append(loss.item())\n",
        "            print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
        "    return a, b, losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evLQuqCqVCzB",
        "outputId": "27754ad5-477a-4386-90a1-12d038004529"
      },
      "source": [
        "a = torch.ones((), requires_grad=True)\n",
        "b = torch.zeros((), requires_grad=True)\n",
        "print(a.shape)\n",
        "a, b, losses = training(30, 0.00005, (a, b), x, y) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([])\n",
            "y_hat: tensor([ 30.0000,  32.4138,  34.8276,  37.2414,  39.6552,  42.0690,  44.4828,\n",
            "         46.8966,  49.3103,  51.7241,  54.1379,  56.5517,  58.9655,  61.3793,\n",
            "         63.7931,  66.2069,  68.6207,  71.0345,  73.4483,  75.8621,  78.2759,\n",
            "         80.6897,  83.1034,  85.5172,  87.9310,  90.3448,  92.7586,  95.1724,\n",
            "         97.5862, 100.0000], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(928658.1763, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "tensor([ 175162.3386,  227370.8543,  250276.4764,  264391.9731,  340779.0067,\n",
            "         340966.0699,  373034.1295,  428344.5940,  489450.9339,  498657.5674,\n",
            "         603520.9373,  638172.9858,  652446.3308,  707559.7349,  789375.2093,\n",
            "         863643.2828, 1002319.9440, 1006782.4616, 1061789.4884, 1129603.1450,\n",
            "        1155311.3363, 1344626.4721, 1366085.4922, 1445892.7362, 1519152.3865,\n",
            "        1650133.4445, 1735546.4487, 1889298.6327, 1907033.3977, 2003017.4784],\n",
            "       dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch 1, Loss 928658.176303\n",
            "y_hat: tensor([227.4489, 245.7420, 264.0352, 282.3283, 300.6215, 318.9147, 337.2078,\n",
            "        355.5010, 373.7934, 392.0865, 410.3797, 428.6729, 446.9660, 465.2592,\n",
            "        483.5523, 501.8455, 520.1387, 538.4318, 556.7250, 575.0181, 593.3113,\n",
            "        611.6045, 629.8969, 648.1900, 666.4832, 684.7763, 703.0695, 721.3627,\n",
            "        739.6558, 757.9490], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(264754.3547, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "tensor([ 48874.2164,  69435.4002,  73478.3038,  72416.7784, 104197.5787,\n",
            "         94296.4911, 101149.5543, 119630.2192, 140718.4767, 133805.5832,\n",
            "        176924.7974, 182103.7287, 176182.4859, 191218.8837, 219687.8029,\n",
            "        243725.3675, 302105.5966, 287283.3231, 299378.6098, 317725.9594,\n",
            "        313396.9705, 395220.3539, 386887.8963, 409318.4125, 427698.7502,\n",
            "        476298.2602, 499976.9636, 559993.7955, 545949.8192, 573550.2612],\n",
            "       dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch 2, Loss 264754.354670\n",
            "y_hat: tensor([ 332.8391,  359.6081,  386.3770,  413.1459,  439.9148,  466.6838,\n",
            "         493.4527,  520.2216,  546.9894,  573.7584,  600.5273,  627.2962,\n",
            "         654.0652,  680.8341,  707.6030,  734.3719,  761.1409,  787.9098,\n",
            "         814.6787,  841.4476,  868.2166,  894.9855,  921.7533,  948.5222,\n",
            "         975.2912, 1002.0601, 1028.8290, 1055.5980, 1082.3669, 1109.1358],\n",
            "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(75608.3487, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "tensor([ 13382.9879,  22392.1108,  22119.7235,  19123.0407,  33673.4081,\n",
            "         25379.1116,  26177.7194,  32817.2694,  40775.1415,  33901.1422,\n",
            "         53119.5096,  52035.4374,  45216.5548,  49155.7316,  59857.5329,\n",
            "         68204.0569,  95258.1170,  82088.1004,  83637.3819,  88353.0178,\n",
            "         81175.6615, 119221.3865, 108996.8320, 115224.7786, 119148.4233,\n",
            "        139024.5056, 145413.3113, 171472.2227, 156953.1402, 164953.1044],\n",
            "       dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch 3, Loss 75608.348718\n",
            "y_hat: tensor([ 389.0923,  420.3852,  451.6782,  482.9711,  514.2641,  545.5570,\n",
            "         576.8500,  608.1429,  639.4346,  670.7276,  702.0205,  733.3135,\n",
            "         764.6064,  795.8994,  827.1923,  858.4853,  889.7783,  921.0712,\n",
            "         952.3642,  983.6571, 1014.9501, 1046.2430, 1077.5347, 1108.8277,\n",
            "        1140.1206, 1171.4136, 1202.7065, 1233.9995, 1265.2924, 1296.5854],\n",
            "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(21720.6759, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "tensor([ 3532.1321,  7896.5949,  6959.8692,  4686.8914, 11914.5780,  6469.7832,\n",
            "         6146.2474,  8692.5882, 11986.6129,  7595.7212, 16636.7377, 14907.3166,\n",
            "        10424.5257, 11373.2862, 15642.1683, 18781.5234, 32400.6272, 23515.8502,\n",
            "        22957.0467, 24035.1920, 19093.6897, 37646.4619, 30403.2585, 32091.9801,\n",
            "        32525.9024, 41414.8686, 43036.9454, 55550.0220, 45474.5242, 47827.3322],\n",
            "       dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch 4, Loss 21720.675909\n",
            "y_hat: tensor([ 419.1179,  452.8256,  486.5333,  520.2410,  553.9487,  587.6564,\n",
            "         621.3641,  655.0718,  688.7781,  722.4858,  756.1935,  789.9012,\n",
            "         823.6089,  857.3166,  891.0243,  924.7320,  958.4397,  992.1474,\n",
            "        1025.8551, 1059.5628, 1093.2705, 1126.9782, 1160.6846, 1194.3923,\n",
            "        1228.1000, 1261.8077, 1295.5154, 1329.2231, 1362.9308, 1396.6385],\n",
            "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(6368.0996, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "tensor([  864.7189,  3183.4872,  2359.1127,   972.8782,  4825.9828,  1469.6176,\n",
            "         1148.1179,  2144.1703,  3616.8053,  1252.8187,  5596.6075,  4291.2685,\n",
            "         1857.4439,  2045.6055,  3749.9295,  5012.4936, 12396.6543,  6768.7744,\n",
            "         6087.8787,  6261.1070,  3583.1543, 12835.0212,  8320.2578,  8756.7943,\n",
            "         8532.2248, 12794.4016, 13143.3931, 19730.9601, 13365.4949, 14075.8130],\n",
            "       dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch 5, Loss 6368.099589\n",
            "y_hat: tensor([ 435.1443,  470.1409,  505.1375,  540.1341,  575.1307,  610.1273,\n",
            "         645.1239,  680.1205,  715.1157,  750.1123,  785.1089,  820.1055,\n",
            "         855.1021,  890.0986,  925.0952,  960.0918,  995.0884, 1030.0850,\n",
            "        1065.0816, 1100.0782, 1135.0748, 1170.0714, 1205.0666, 1240.0632,\n",
            "        1275.0598, 1310.0564, 1345.0529, 1380.0495, 1415.0461, 1450.0427],\n",
            "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(1994.1602, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "tensor([ 179.0152, 1529.3622,  897.9890,  127.6418, 2331.6606,  251.6879,\n",
            "         102.4970,  451.8380, 1142.5979,   60.3533, 2106.3641, 1246.3404,\n",
            "         134.6749,  154.9117,  737.9784, 1255.9341, 5578.8298, 1965.5894,\n",
            "        1505.3136, 1490.8692,  325.9895, 4927.8410, 2193.3707, 2295.0653,\n",
            "        2062.0902, 4207.2927, 4238.9280, 8035.4110, 4031.4700, 4255.9003],\n",
            "       dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch 6, Loss 1994.160233\n",
            "y_hat: tensor([ 443.6986,  479.3832,  515.0677,  550.7523,  586.4369,  622.1214,\n",
            "         657.8060,  693.4905,  729.1736,  764.8582,  800.5427,  836.2273,\n",
            "         871.9118,  907.5964,  943.2810,  978.9655, 1014.6501, 1050.3346,\n",
            "        1086.0192, 1121.7038, 1157.3883, 1193.0729, 1228.7560, 1264.4405,\n",
            "        1300.1251, 1335.8096, 1371.4942, 1407.1788, 1442.8633, 1478.5479],\n",
            "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(748.0232, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "tensor([2.3284e+01, 8.9191e+02, 4.0145e+02, 4.6200e-01, 1.3676e+03, 1.4981e+01,\n",
            "        6.5432e+00, 6.2196e+01, 3.8984e+02, 4.8681e+01, 9.2789e+02, 3.6794e+02,\n",
            "        2.7090e+01, 2.5517e+01, 8.0641e+01, 2.7442e+02, 3.0393e+03, 5.8010e+02,\n",
            "        3.1901e+02, 2.8853e+02, 1.8133e+01, 2.2276e+03, 5.3565e+02, 5.5364e+02,\n",
            "        4.1392e+02, 1.5296e+03, 1.4950e+03, 3.9077e+03, 1.2728e+03, 1.3492e+03],\n",
            "       dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch 7, Loss 748.023193\n",
            "y_hat: tensor([ 448.2645,  484.3163,  520.3680,  556.4198,  592.4716,  628.5233,\n",
            "         664.5751,  700.6269,  736.6772,  772.7289,  808.7807,  844.8324,\n",
            "         880.8842,  916.9360,  952.9877,  989.0395, 1025.0913, 1061.1430,\n",
            "        1097.1948, 1133.2466, 1169.2983, 1205.3501, 1241.4004, 1277.4521,\n",
            "        1313.5039, 1349.5557, 1385.6074, 1421.6592, 1457.7110, 1493.7627],\n",
            "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(392.9998, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "tensor([6.7332e-02, 6.2159e+02, 2.1715e+02, 2.4878e+01, 9.5768e+02, 6.4077e+00,\n",
            "        8.6995e+01, 5.6268e-01, 1.4984e+02, 2.2046e+02, 4.9388e+02, 1.1186e+02,\n",
            "        2.0099e+02, 2.0710e+02, 5.2816e-01, 4.2139e+01, 1.9971e+03, 1.7628e+02,\n",
            "        4.4692e+01, 2.9631e+01, 2.6142e+02, 1.2194e+03, 1.1024e+02, 1.1063e+02,\n",
            "        4.8526e+01, 6.4335e+02, 6.0283e+02, 2.3070e+03, 4.3385e+02, 4.6299e+02],\n",
            "       dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch 8, Loss 392.999771\n",
            "y_hat: tensor([ 450.7016,  486.9494,  523.1971,  559.4449,  595.6927,  631.9404,\n",
            "         668.1882,  704.4360,  740.6822,  776.9300,  813.1778,  849.4255,\n",
            "         885.6733,  921.9211,  958.1689,  994.4166, 1030.6644, 1066.9122,\n",
            "        1103.1599, 1139.4077, 1175.6555, 1211.9032, 1248.1495, 1284.3973,\n",
            "        1320.6450, 1356.8928, 1393.1406, 1429.3883, 1465.6361, 1501.8839],\n",
            "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(291.8533, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "tensor([4.7419e+00, 4.9723e+02, 1.4177e+02, 6.4207e+01, 7.6869e+02, 3.5384e+01,\n",
            "        1.6745e+02, 9.3573e+00, 6.7828e+01, 3.6286e+02, 3.1777e+02, 3.5802e+01,\n",
            "        3.5972e+02, 3.7543e+02, 3.4903e+01, 1.2418e+00, 1.5300e+03, 5.6368e+01,\n",
            "        5.1851e-01, 5.1508e-01, 5.0740e+02, 8.0467e+02, 1.4066e+01, 1.2764e+01,\n",
            "        3.0635e-02, 3.2498e+02, 2.8966e+02, 1.6242e+03, 1.6651e+02, 1.7946e+02],\n",
            "       dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch 9, Loss 291.853276\n",
            "y_hat: tensor([ 452.0024,  488.3548,  524.7072,  561.0595,  597.4119,  633.7643,\n",
            "         670.1167,  706.4691,  742.8200,  779.1724,  815.5247,  851.8771,\n",
            "         888.2295,  924.5819,  960.9343,  997.2867, 1033.6391, 1069.9914,\n",
            "        1106.3438, 1142.6962, 1179.0486, 1215.4010, 1251.7519, 1288.1043,\n",
            "        1324.4566, 1360.8090, 1397.1614, 1433.5138, 1469.8662, 1506.2186],\n",
            "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(263.0368, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "tensor([1.2099e+01, 4.3653e+02, 1.0809e+02, 9.2690e+01, 6.7632e+02, 6.0409e+01,\n",
            "        2.2108e+02, 2.5929e+01, 3.7186e+01, 4.5332e+02, 2.3961e+02, 1.2474e+01,\n",
            "        4.6322e+02, 4.8562e+02, 7.5226e+01, 3.0824e+00, 1.3062e+03, 1.9612e+01,\n",
            "        6.0704e+00, 1.6050e+01, 6.7177e+02, 6.1847e+02, 2.1944e-02, 1.8024e-02,\n",
            "        1.5893e+01, 1.9912e+02, 1.6896e+02, 1.3087e+03, 7.5235e+01, 8.2110e+01],\n",
            "       dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch 10, Loss 263.036789\n",
            "y_hat: tensor([ 452.6967,  489.1049,  525.5132,  561.9214,  598.3296,  634.7378,\n",
            "         671.1461,  707.5543,  743.9610,  780.3693,  816.7775,  853.1857,\n",
            "         889.5939,  926.0022,  962.4104,  998.8186, 1035.2269, 1071.6351,\n",
            "        1108.0433, 1144.4516, 1180.8598, 1217.2680, 1253.6747, 1290.0830,\n",
            "        1326.4912, 1362.8994, 1399.3077, 1435.7159, 1472.1241, 1508.5323],\n",
            "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(254.8266, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "tensor([  17.4114,  405.7435,   91.9843,  110.0272,  629.4271,   76.4898,\n",
            "         252.7487,   38.1591,   24.5716,  505.7216,  202.3937,    4.9430,\n",
            "         523.8122,  550.2390,  103.0104,   10.8085, 1193.9193,    7.7557,\n",
            "          17.3333,   33.1955,  768.9408,  529.0914,    3.1497,    4.4646,\n",
            "          36.2548,  144.4943,  117.7734, 1154.2406,   41.1636,   45.5309],\n",
            "       dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch 11, Loss 254.826636\n",
            "y_hat: tensor([ 453.0673,  489.5053,  525.9433,  562.3814,  598.8194,  635.2575,\n",
            "         671.6955,  708.1335,  744.5701,  781.0081,  817.4461,  853.8842,\n",
            "         890.3222,  926.7603,  963.1983,  999.6363, 1036.0744, 1072.5124,\n",
            "        1108.9504, 1145.3885, 1181.8265, 1218.2646, 1254.7011, 1291.1391,\n",
            "        1327.5772, 1364.0152, 1400.4532, 1436.8913, 1473.3293, 1509.7674],\n",
            "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(252.4875, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "tensor([  20.6413,  389.7738,   83.9175,  119.8891,  605.0899,   85.8488,\n",
            "         270.5203,   45.6508,   18.9045,  534.8631,  183.8154,    2.3251,\n",
            "         557.6787,  586.3788,  119.6245,   16.8538, 1136.0693,    3.6389,\n",
            "          25.7095,   44.8697,  823.4906,  484.2392,    7.8461,   10.0434,\n",
            "          50.5118,  118.9145,   94.2211, 1075.7558,   27.1512,   30.3892],\n",
            "       dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch 12, Loss 252.487520\n",
            "y_hat: tensor([ 453.2651,  489.7190,  526.1729,  562.6269,  599.0808,  635.5348,\n",
            "         671.9887,  708.4427,  744.8951,  781.3491,  817.8030,  854.2570,\n",
            "         890.7109,  927.1649,  963.6188, 1000.0728, 1036.5267, 1072.9807,\n",
            "        1109.4346, 1145.8886, 1182.3425, 1218.7965, 1255.2489, 1291.7029,\n",
            "        1328.1568, 1364.6108, 1401.0647, 1437.5187, 1473.9726, 1510.4266],\n",
            "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(251.8211, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "tensor([  22.4776,  381.3818,   79.7637,  125.3258,  592.2970,   91.0650,\n",
            "         280.2526,   49.9241,   16.1834,  550.7510,  174.2655,    1.3271,\n",
            "         576.1888,  606.1386,  129.0004,   20.6278, 1105.7799,    2.0716,\n",
            "          30.8539,   51.8195,  853.3718,  461.1121,   11.2152,   13.9343,\n",
            "          59.0871,  106.2803,   82.7242, 1034.9948,   20.8610,   23.5559],\n",
            "       dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch 13, Loss 251.821067\n",
            "y_hat: tensor([ 453.3706,  489.8330,  526.2955,  562.7579,  599.2204,  635.6828,\n",
            "         672.1453,  708.6077,  745.0686,  781.5311,  817.9935,  854.4560,\n",
            "         890.9184,  927.3809,  963.8433, 1000.3057, 1036.7682, 1073.2306,\n",
            "        1109.6931, 1146.1555, 1182.6180, 1219.0804, 1255.5413, 1292.0038,\n",
            "        1328.4662, 1364.9287, 1401.3911, 1437.8536, 1474.3160, 1510.7784],\n",
            "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(251.6311, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "tensor([2.3490e+01, 3.7694e+02, 7.7590e+01, 1.2828e+02, 5.8552e+02, 9.3912e+01,\n",
            "        2.8552e+02, 5.2283e+01, 1.4818e+01, 5.5933e+02, 1.6927e+02, 9.0826e-01,\n",
            "        5.8619e+02, 6.1682e+02, 1.3415e+02, 2.2798e+01, 1.0898e+03, 1.4146e+00,\n",
            "        3.3792e+01, 5.5734e+01, 8.6954e+02, 4.4900e+02, 1.3259e+01, 1.6271e+01,\n",
            "        6.3940e+01, 9.9827e+01, 7.6893e+01, 1.0136e+03, 1.7842e+01, 2.0264e+01],\n",
            "       dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch 14, Loss 251.631127\n",
            "y_hat: tensor([ 453.4269,  489.8939,  526.3609,  562.8279,  599.2948,  635.7618,\n",
            "         672.2288,  708.6958,  745.1612,  781.6282,  818.0952,  854.5622,\n",
            "         891.0292,  927.4961,  963.9631, 1000.4301, 1036.8971, 1073.3640,\n",
            "        1109.8310, 1146.2980, 1182.7650, 1219.2320, 1255.6974, 1292.1644,\n",
            "        1328.6314, 1365.0984, 1401.5653, 1438.0323, 1474.4993, 1510.9663],\n",
            "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(251.5770, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "tensor([2.4039e+01, 3.7458e+02, 7.6442e+01, 1.2987e+02, 5.8193e+02, 9.5449e+01,\n",
            "        2.8835e+02, 5.3564e+01, 1.4113e+01, 5.6393e+02, 1.6664e+02, 7.1711e-01,\n",
            "        5.9157e+02, 6.2256e+02, 1.3694e+02, 2.4001e+01, 1.0813e+03, 1.1150e+00,\n",
            "        3.5415e+01, 5.7882e+01, 8.7823e+02, 4.4260e+02, 1.4420e+01, 1.7593e+01,\n",
            "        6.6608e+01, 9.6464e+01, 7.3868e+01, 1.0022e+03, 1.6327e+01, 1.8608e+01],\n",
            "       dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch 15, Loss 251.576954\n",
            "y_hat: tensor([ 453.4570,  489.9264,  526.3958,  562.8652,  599.3346,  635.8040,\n",
            "         672.2734,  708.7428,  745.2107,  781.6801,  818.1495,  854.6189,\n",
            "         891.0883,  927.5577,  964.0271, 1000.4965, 1036.9659, 1073.4353,\n",
            "        1109.9047, 1146.3741, 1182.8435, 1219.3129, 1255.7808, 1292.2502,\n",
            "        1328.7196, 1365.1890, 1401.6584, 1438.1278, 1474.5972, 1511.0666],\n",
            "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(251.5615, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "tensor([2.4334e+01, 3.7333e+02, 7.5833e+01, 1.3072e+02, 5.8001e+02, 9.6275e+01,\n",
            "        2.8986e+02, 5.4255e+01, 1.3744e+01, 5.6640e+02, 1.6524e+02, 6.2432e-01,\n",
            "        5.9445e+02, 6.2563e+02, 1.3844e+02, 2.4656e+01, 1.0768e+03, 9.6971e-01,\n",
            "        3.6297e+01, 5.9045e+01, 8.8289e+02, 4.3920e+02, 1.5060e+01, 1.8320e+01,\n",
            "        6.8055e+01, 9.4693e+01, 7.2278e+01, 9.9618e+02, 1.5546e+01, 1.7753e+01],\n",
            "       dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch 16, Loss 251.561457\n",
            "y_hat: tensor([ 453.4730,  489.9437,  526.4144,  562.8851,  599.3558,  635.8265,\n",
            "         672.2972,  708.7678,  745.2370,  781.7077,  818.1784,  854.6491,\n",
            "         891.1198,  927.5905,  964.0612, 1000.5319, 1037.0026, 1073.4733,\n",
            "        1109.9440, 1146.4147, 1182.8854, 1219.3560, 1255.8252, 1292.2959,\n",
            "        1328.7666, 1365.2373, 1401.7080, 1438.1787, 1474.6494, 1511.1201],\n",
            "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(251.5570, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "tensor([2.4492e+01, 3.7266e+02, 7.5510e+01, 1.3117e+02, 5.7899e+02, 9.6717e+01,\n",
            "        2.9067e+02, 5.4625e+01, 1.3550e+01, 5.6771e+02, 1.6450e+02, 5.7743e-01,\n",
            "        5.9598e+02, 6.2728e+02, 1.3924e+02, 2.5009e+01, 1.0744e+03, 8.9629e-01,\n",
            "        3.6772e+01, 5.9670e+01, 8.8538e+02, 4.3739e+02, 1.5407e+01, 1.8714e+01,\n",
            "        6.8834e+01, 9.3754e+01, 7.1436e+01, 9.9296e+02, 1.5137e+01, 1.7305e+01],\n",
            "       dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch 17, Loss 251.556977\n",
            "y_hat: tensor([ 453.4815,  489.9529,  526.4243,  562.8957,  599.3670,  635.8384,\n",
            "         672.3098,  708.7812,  745.2511,  781.7225,  818.1938,  854.6652,\n",
            "         891.1366,  927.6080,  964.0794, 1000.5508, 1037.0221, 1073.4935,\n",
            "        1109.9649, 1146.4363, 1182.9077, 1219.3791, 1255.8489, 1292.3203,\n",
            "        1328.7917, 1365.2631, 1401.7345, 1438.2059, 1474.6773, 1511.1486],\n",
            "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(251.5556, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "tensor([2.4577e+01, 3.7230e+02, 7.5338e+01, 1.3142e+02, 5.7845e+02, 9.6952e+01,\n",
            "        2.9111e+02, 5.4822e+01, 1.3446e+01, 5.6842e+02, 1.6410e+02, 5.5320e-01,\n",
            "        5.9681e+02, 6.2815e+02, 1.3967e+02, 2.5198e+01, 1.0731e+03, 8.5834e-01,\n",
            "        3.7026e+01, 6.0005e+01, 8.8671e+02, 4.3643e+02, 1.5594e+01, 1.8925e+01,\n",
            "        6.9251e+01, 9.3256e+01, 7.0989e+01, 9.9125e+02, 1.4921e+01, 1.7068e+01],\n",
            "       dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch 18, Loss 251.555637\n",
            "y_hat: tensor([ 453.4860,  489.9578,  526.4296,  562.9013,  599.3731,  635.8448,\n",
            "         672.3166,  708.7883,  745.2586,  781.7303,  818.2021,  854.6738,\n",
            "         891.1456,  927.6174,  964.0891, 1000.5609, 1037.0326, 1073.5044,\n",
            "        1109.9761, 1146.4479, 1182.9196, 1219.3914, 1255.8616, 1292.3334,\n",
            "        1328.8051, 1365.2769, 1401.7487, 1438.2204, 1474.6922, 1511.1639],\n",
            "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(251.5552, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "tensor([2.4622e+01, 3.7211e+02, 7.5246e+01, 1.3155e+02, 5.7816e+02, 9.7078e+01,\n",
            "        2.9134e+02, 5.4928e+01, 1.3391e+01, 5.6879e+02, 1.6389e+02, 5.4046e-01,\n",
            "        5.9725e+02, 6.2862e+02, 1.3990e+02, 2.5300e+01, 1.0724e+03, 8.3837e-01,\n",
            "        3.7163e+01, 6.0185e+01, 8.8742e+02, 4.3592e+02, 1.5695e+01, 1.9039e+01,\n",
            "        6.9475e+01, 9.2989e+01, 7.0751e+01, 9.9033e+02, 1.4806e+01, 1.6942e+01],\n",
            "       dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch 19, Loss 251.555189\n",
            "y_hat: tensor([ 453.4884,  489.9604,  526.4323,  562.9043,  599.3763,  635.8482,\n",
            "         672.3202,  708.7921,  745.2626,  781.7345,  818.2065,  854.6784,\n",
            "         891.1504,  927.6223,  964.0943, 1000.5662, 1037.0382, 1073.5101,\n",
            "        1109.9821, 1146.4540, 1182.9260, 1219.3979, 1255.8684, 1292.3403,\n",
            "        1328.8123, 1365.2842, 1401.7562, 1438.2282, 1474.7001, 1511.1721],\n",
            "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(251.5550, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "tensor([2.4646e+01, 3.7201e+02, 7.5198e+01, 1.3161e+02, 5.7801e+02, 9.7145e+01,\n",
            "        2.9146e+02, 5.4984e+01, 1.3362e+01, 5.6899e+02, 1.6378e+02, 5.3376e-01,\n",
            "        5.9748e+02, 6.2887e+02, 1.4003e+02, 2.5354e+01, 1.0720e+03, 8.2786e-01,\n",
            "        3.7235e+01, 6.0280e+01, 8.8780e+02, 4.3564e+02, 1.5748e+01, 1.9100e+01,\n",
            "        6.9594e+01, 9.2848e+01, 7.0624e+01, 9.8985e+02, 1.4745e+01, 1.6875e+01],\n",
            "       dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch 20, Loss 251.554995\n",
            "y_hat: tensor([ 453.4897,  489.9617,  526.4338,  562.9059,  599.3779,  635.8500,\n",
            "         672.3220,  708.7941,  745.2646,  781.7367,  818.2088,  854.6808,\n",
            "         891.1529,  927.6249,  964.0970, 1000.5691, 1037.0411, 1073.5132,\n",
            "        1109.9852, 1146.4573, 1182.9294, 1219.4014, 1255.8720, 1292.3440,\n",
            "        1328.8161, 1365.2881, 1401.7602, 1438.2323, 1474.7043, 1511.1764],\n",
            "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(251.5549, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "tensor([2.4658e+01, 3.7196e+02, 7.5172e+01, 1.3165e+02, 5.7793e+02, 9.7180e+01,\n",
            "        2.9152e+02, 5.5013e+01, 1.3347e+01, 5.6909e+02, 1.6372e+02, 5.3024e-01,\n",
            "        5.9760e+02, 6.2900e+02, 1.4009e+02, 2.5382e+01, 1.0718e+03, 8.2232e-01,\n",
            "        3.7274e+01, 6.0331e+01, 8.8800e+02, 4.3550e+02, 1.5777e+01, 1.9132e+01,\n",
            "        6.9657e+01, 9.2773e+01, 7.0557e+01, 9.8959e+02, 1.4712e+01, 1.6840e+01],\n",
            "       dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch 21, Loss 251.554874\n",
            "y_hat: tensor([ 453.4903,  489.9625,  526.4346,  562.9067,  599.3788,  635.8509,\n",
            "         672.3230,  708.7952,  745.2658,  781.7379,  818.2100,  854.6821,\n",
            "         891.1542,  927.6263,  964.0985, 1000.5706, 1037.0427, 1073.5148,\n",
            "        1109.9869, 1146.4590, 1182.9312, 1219.4033, 1255.8739, 1292.3460,\n",
            "        1328.8181, 1365.2902, 1401.7623, 1438.2345, 1474.7066, 1511.1787],\n",
            "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(251.5548, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "tensor([2.4664e+01, 3.7193e+02, 7.5159e+01, 1.3167e+02, 5.7788e+02, 9.7198e+01,\n",
            "        2.9156e+02, 5.5029e+01, 1.3339e+01, 5.6915e+02, 1.6369e+02, 5.2837e-01,\n",
            "        5.9767e+02, 6.2907e+02, 1.4013e+02, 2.5397e+01, 1.0717e+03, 8.1937e-01,\n",
            "        3.7295e+01, 6.0358e+01, 8.8811e+02, 4.3542e+02, 1.5792e+01, 1.9149e+01,\n",
            "        6.9691e+01, 9.2732e+01, 7.0521e+01, 9.8945e+02, 1.4695e+01, 1.6821e+01],\n",
            "       dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch 22, Loss 251.554774\n",
            "y_hat: tensor([ 453.4907,  489.9628,  526.4350,  562.9071,  599.3793,  635.8514,\n",
            "         672.3236,  708.7957,  745.2663,  781.7385,  818.2106,  854.6828,\n",
            "         891.1549,  927.6271,  964.0992, 1000.5714, 1037.0435, 1073.5157,\n",
            "        1109.9878, 1146.4600, 1182.9321, 1219.4043, 1255.8749, 1292.3471,\n",
            "        1328.8192, 1365.2914, 1401.7635, 1438.2357, 1474.7078, 1511.1800],\n",
            "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(251.5547, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "tensor([2.4668e+01, 3.7192e+02, 7.5152e+01, 1.3168e+02, 5.7786e+02, 9.7208e+01,\n",
            "        2.9157e+02, 5.5037e+01, 1.3335e+01, 5.6918e+02, 1.6367e+02, 5.2737e-01,\n",
            "        5.9770e+02, 6.2911e+02, 1.4014e+02, 2.5406e+01, 1.0717e+03, 8.1778e-01,\n",
            "        3.7306e+01, 6.0373e+01, 8.8817e+02, 4.3538e+02, 1.5800e+01, 1.9159e+01,\n",
            "        6.9709e+01, 9.2711e+01, 7.0501e+01, 9.8938e+02, 1.4686e+01, 1.6810e+01],\n",
            "       dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch 23, Loss 251.554679\n",
            "y_hat: tensor([ 453.4908,  489.9630,  526.4352,  562.9073,  599.3795,  635.8517,\n",
            "         672.3238,  708.7960,  745.2667,  781.7388,  818.2110,  854.6832,\n",
            "         891.1553,  927.6275,  964.0997, 1000.5718, 1037.0440, 1073.5162,\n",
            "        1109.9883, 1146.4605, 1182.9327, 1219.4048, 1255.8755, 1292.3477,\n",
            "        1328.8198, 1365.2920, 1401.7642, 1438.2363, 1474.7085, 1511.1807],\n",
            "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(251.5546, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "tensor([2.4669e+01, 3.7191e+02, 7.5149e+01, 1.3168e+02, 5.7785e+02, 9.7213e+01,\n",
            "        2.9158e+02, 5.5042e+01, 1.3332e+01, 5.6920e+02, 1.6366e+02, 5.2685e-01,\n",
            "        5.9772e+02, 6.2913e+02, 1.4015e+02, 2.5410e+01, 1.0716e+03, 8.1692e-01,\n",
            "        3.7312e+01, 6.0381e+01, 8.8820e+02, 4.3536e+02, 1.5805e+01, 1.9164e+01,\n",
            "        6.9720e+01, 9.2699e+01, 7.0490e+01, 9.8933e+02, 1.4680e+01, 1.6805e+01],\n",
            "       dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch 24, Loss 251.554586\n",
            "y_hat: tensor([ 453.4909,  489.9631,  526.4353,  562.9074,  599.3796,  635.8518,\n",
            "         672.3240,  708.7962,  745.2668,  781.7390,  818.2112,  854.6834,\n",
            "         891.1555,  927.6277,  964.0999, 1000.5721, 1037.0443, 1073.5164,\n",
            "        1109.9886, 1146.4608, 1182.9330, 1219.4051, 1255.8758, 1292.3480,\n",
            "        1328.8202, 1365.2924, 1401.7645, 1438.2367, 1474.7089, 1511.1811],\n",
            "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(251.5545, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "tensor([2.4670e+01, 3.7191e+02, 7.5147e+01, 1.3169e+02, 5.7784e+02, 9.7216e+01,\n",
            "        2.9159e+02, 5.5044e+01, 1.3331e+01, 5.6920e+02, 1.6366e+02, 5.2655e-01,\n",
            "        5.9773e+02, 6.2914e+02, 1.4016e+02, 2.5412e+01, 1.0716e+03, 8.1643e-01,\n",
            "        3.7315e+01, 6.0385e+01, 8.8822e+02, 4.3534e+02, 1.5807e+01, 1.9167e+01,\n",
            "        6.9725e+01, 9.2692e+01, 7.0484e+01, 9.8931e+02, 1.4677e+01, 1.6801e+01],\n",
            "       dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch 25, Loss 251.554493\n",
            "y_hat: tensor([ 453.4909,  489.9631,  526.4353,  562.9075,  599.3797,  635.8519,\n",
            "         672.3240,  708.7962,  745.2669,  781.7391,  818.2113,  854.6835,\n",
            "         891.1556,  927.6278,  964.1000, 1000.5722, 1037.0444, 1073.5166,\n",
            "        1109.9888, 1146.4609, 1182.9331, 1219.4053, 1255.8760, 1292.3482,\n",
            "        1328.8204, 1365.2925, 1401.7647, 1438.2369, 1474.7091, 1511.1813],\n",
            "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(251.5544, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "tensor([2.4670e+01, 3.7191e+02, 7.5146e+01, 1.3169e+02, 5.7784e+02, 9.7217e+01,\n",
            "        2.9159e+02, 5.5045e+01, 1.3331e+01, 5.6921e+02, 1.6365e+02, 5.2642e-01,\n",
            "        5.9774e+02, 6.2915e+02, 1.4016e+02, 2.5414e+01, 1.0716e+03, 8.1619e-01,\n",
            "        3.7317e+01, 6.0388e+01, 8.8823e+02, 4.3534e+02, 1.5808e+01, 1.9168e+01,\n",
            "        6.9728e+01, 9.2688e+01, 7.0481e+01, 9.8930e+02, 1.4676e+01, 1.6799e+01],\n",
            "       dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch 26, Loss 251.554401\n",
            "y_hat: tensor([ 453.4909,  489.9631,  526.4353,  562.9075,  599.3797,  635.8519,\n",
            "         672.3241,  708.7962,  745.2669,  781.7391,  818.2113,  854.6835,\n",
            "         891.1557,  927.6279,  964.1001, 1000.5723, 1037.0444, 1073.5166,\n",
            "        1109.9888, 1146.4610, 1182.9332, 1219.4054, 1255.8761, 1292.3483,\n",
            "        1328.8205, 1365.2926, 1401.7648, 1438.2370, 1474.7092, 1511.1814],\n",
            "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(251.5543, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "tensor([2.4670e+01, 3.7191e+02, 7.5146e+01, 1.3169e+02, 5.7784e+02, 9.7217e+01,\n",
            "        2.9159e+02, 5.5045e+01, 1.3330e+01, 5.6921e+02, 1.6365e+02, 5.2636e-01,\n",
            "        5.9774e+02, 6.2915e+02, 1.4016e+02, 2.5414e+01, 1.0716e+03, 8.1607e-01,\n",
            "        3.7318e+01, 6.0389e+01, 8.8823e+02, 4.3533e+02, 1.5809e+01, 1.9169e+01,\n",
            "        6.9730e+01, 9.2686e+01, 7.0479e+01, 9.8929e+02, 1.4675e+01, 1.6798e+01],\n",
            "       dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch 27, Loss 251.554308\n",
            "y_hat: tensor([ 453.4909,  489.9631,  526.4353,  562.9075,  599.3797,  635.8519,\n",
            "         672.3241,  708.7963,  745.2669,  781.7391,  818.2113,  854.6835,\n",
            "         891.1557,  927.6279,  964.1001, 1000.5723, 1037.0445, 1073.5167,\n",
            "        1109.9889, 1146.4611, 1182.9333, 1219.4055, 1255.8762, 1292.3484,\n",
            "        1328.8206, 1365.2928, 1401.7649, 1438.2371, 1474.7093, 1511.1815],\n",
            "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(251.5542, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "tensor([2.4670e+01, 3.7191e+02, 7.5147e+01, 1.3169e+02, 5.7784e+02, 9.7217e+01,\n",
            "        2.9159e+02, 5.5045e+01, 1.3330e+01, 5.6921e+02, 1.6365e+02, 5.2630e-01,\n",
            "        5.9774e+02, 6.2915e+02, 1.4016e+02, 2.5415e+01, 1.0716e+03, 8.1594e-01,\n",
            "        3.7319e+01, 6.0390e+01, 8.8824e+02, 4.3533e+02, 1.5810e+01, 1.9170e+01,\n",
            "        6.9732e+01, 9.2684e+01, 7.0477e+01, 9.8928e+02, 1.4674e+01, 1.6797e+01],\n",
            "       dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch 28, Loss 251.554216\n",
            "y_hat: tensor([ 453.4909,  489.9631,  526.4353,  562.9075,  599.3797,  635.8518,\n",
            "         672.3240,  708.7962,  745.2669,  781.7391,  818.2113,  854.6835,\n",
            "         891.1557,  927.6279,  964.1001, 1000.5723, 1037.0445, 1073.5167,\n",
            "        1109.9889, 1146.4611, 1182.9333, 1219.4055, 1255.8762, 1292.3484,\n",
            "        1328.8206, 1365.2928, 1401.7650, 1438.2372, 1474.7094, 1511.1816],\n",
            "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(251.5541, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "tensor([2.4670e+01, 3.7191e+02, 7.5147e+01, 1.3169e+02, 5.7784e+02, 9.7217e+01,\n",
            "        2.9159e+02, 5.5045e+01, 1.3330e+01, 5.6921e+02, 1.6365e+02, 5.2632e-01,\n",
            "        5.9774e+02, 6.2915e+02, 1.4016e+02, 2.5415e+01, 1.0716e+03, 8.1595e-01,\n",
            "        3.7319e+01, 6.0390e+01, 8.8824e+02, 4.3533e+02, 1.5810e+01, 1.9170e+01,\n",
            "        6.9732e+01, 9.2684e+01, 7.0477e+01, 9.8928e+02, 1.4674e+01, 1.6797e+01],\n",
            "       dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch 29, Loss 251.554124\n",
            "y_hat: tensor([ 453.4908,  489.9630,  526.4352,  562.9074,  599.3796,  635.8518,\n",
            "         672.3240,  708.7962,  745.2669,  781.7391,  818.2113,  854.6835,\n",
            "         891.1557,  927.6279,  964.1001, 1000.5723, 1037.0445, 1073.5167,\n",
            "        1109.9889, 1146.4611, 1182.9333, 1219.4055, 1255.8762, 1292.3484,\n",
            "        1328.8206, 1365.2928, 1401.7650, 1438.2372, 1474.7094, 1511.1816],\n",
            "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(251.5540, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "tensor([2.4669e+01, 3.7191e+02, 7.5148e+01, 1.3169e+02, 5.7784e+02, 9.7216e+01,\n",
            "        2.9159e+02, 5.5045e+01, 1.3330e+01, 5.6921e+02, 1.6365e+02, 5.2634e-01,\n",
            "        5.9774e+02, 6.2915e+02, 1.4016e+02, 2.5415e+01, 1.0716e+03, 8.1595e-01,\n",
            "        3.7319e+01, 6.0390e+01, 8.8824e+02, 4.3533e+02, 1.5810e+01, 1.9170e+01,\n",
            "        6.9732e+01, 9.2683e+01, 7.0476e+01, 9.8928e+02, 1.4674e+01, 1.6797e+01],\n",
            "       dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch 30, Loss 251.554031\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "CsEcf-BTVblx",
        "outputId": "ca968447-7402-4d20-ef30-aa9c4fb2bcd0"
      },
      "source": [
        "plt.plot(losses)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4YIfIfHVdKW",
        "outputId": "46a557c0-79a2-4d21-8ecf-83088e706100"
      },
      "source": [
        "x = torch.tensor([50])\n",
        "with torch.no_grad():\n",
        "    y_hat = model(x, a, b)\n",
        "    print(y_hat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([755.6882])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "nujn6a7nVpLu",
        "outputId": "37ff6b26-8881-4343-9ce4-82e73eb8f200"
      },
      "source": [
        "x = torch.tensor(data[:,0])\n",
        "y = torch.tensor(data[:,1])\n",
        "with torch.no_grad():\n",
        "    y_hat = model(x, a, b)\n",
        "plt.scatter(x, y)\n",
        "plt.plot(x, y_hat, c='r')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fa72c4ffb90>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}